{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T07:32:33.756717Z",
     "start_time": "2022-12-08T07:32:31.847163Z"
    },
    "code_folding": [
     0,
     24,
     30,
     44,
     70
    ]
   },
   "outputs": [],
   "source": [
    "#模块\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import stats\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "res = pd.DataFrame(0,columns=[\"spnsi\",\"speci\",\"GM\",\"f1\",\"AUC\"],index=dataList)\n",
    "def GM_score(x,y): #计算GM 传入numpy\n",
    "    cm1 = confusion_matrix(x,y)\n",
    "    sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    return sensitivity1,specificity1\n",
    "\n",
    "def myknn(train,label,x_test):\n",
    "    predictList = []\n",
    "    for j in range(x_test.shape[0]):\n",
    "        test = x_test.iloc[j,:]\n",
    "        maxJcd = 0\n",
    "        prediction = 0\n",
    "        for i in range(train.shape[0]):\n",
    "            temp = jaccard_score(train.iloc[i,:],test)\n",
    "            if(temp > maxJcd):\n",
    "                prediction = label[i]\n",
    "                maxJcd = temp\n",
    "        predictList.append(prediction)\n",
    "    return predictList\n",
    "\n",
    "def fisher_score(X, y):\n",
    "\n",
    "    # Construct weight matrix W in a fisherScore way\n",
    "    kwargs = {\"neighbor_mode\": \"supervised\", \"fisher_score\": True, 'y': y}\n",
    "    W = construct_W(X, **kwargs)\n",
    "\n",
    "    # build the diagonal D matrix from affinity matrix W\n",
    "    D = np.array(W.sum(axis=1))\n",
    "    L = W\n",
    "    tmp = np.dot(np.transpose(D), X)\n",
    "    D = diags(np.transpose(D), [0])\n",
    "    Xt = np.transpose(X)\n",
    "    t1 = np.transpose(np.dot(Xt, D.todense()))\n",
    "    t2 = np.transpose(np.dot(Xt, L.todense()))\n",
    "    # compute the numerator of Lr\n",
    "    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    # compute the denominator of Lr\n",
    "    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
    "    # avoid the denominator of Lr to be 0\n",
    "    D_prime[D_prime < 1e-12] = 10000\n",
    "    lap_score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
    "\n",
    "    # compute fisher score from laplacian score, where fisher_score = 1/lap_score - 1\n",
    "    score = 1.0/lap_score - 1\n",
    "    return np.transpose(score)\n",
    "\n",
    "def construct_W(X, **kwargs):\n",
    "    \"\"\"\n",
    "    Construct the affinity matrix W through different ways\n",
    "    Notes\n",
    "    -----\n",
    "    if kwargs is null, use the default parameter settings;\n",
    "    if kwargs is not null, construct the affinity matrix according to parameters in kwargs\n",
    "    Input\n",
    "    -----\n",
    "    X: {numpy array}, shape (n_samples, n_features)\n",
    "        input data\n",
    "    kwargs: {dictionary}\n",
    "        parameters to construct different affinity matrix W:\n",
    "        y: {numpy array}, shape (n_samples, 1)\n",
    "            the true label information needed under the 'supervised' neighbor mode\n",
    "        metric: {string}\n",
    "            choices for different distance measures\n",
    "            'euclidean' - use euclidean distance\n",
    "            'cosine' - use cosine distance (default)\n",
    "        neighbor_mode: {string}\n",
    "            indicates how to construct the graph\n",
    "            'knn' - put an edge between two nodes if and only if they are among the\n",
    "                    k nearest neighbors of each other (default)\n",
    "            'supervised' - put an edge between two nodes if they belong to same class\n",
    "                    and they are among the k nearest neighbors of each other\n",
    "        weight_mode: {string}\n",
    "            indicates how to assign weights for each edge in the graph\n",
    "            'binary' - 0-1 weighting, every edge receives weight of 1 (default)\n",
    "            'heat_kernel' - if nodes i and j are connected, put weight W_ij = exp(-norm(x_i - x_j)/2t^2)\n",
    "                            this weight mode can only be used under 'euclidean' metric and you are required\n",
    "                            to provide the parameter t\n",
    "            'cosine' - if nodes i and j are connected, put weight cosine(x_i,x_j).\n",
    "                        this weight mode can only be used under 'cosine' metric\n",
    "        k: {int}\n",
    "            choices for the number of neighbors (default k = 5)\n",
    "        t: {float}\n",
    "            parameter for the 'heat_kernel' weight_mode\n",
    "        fisher_score: {boolean}\n",
    "            indicates whether to build the affinity matrix in a fisher score way, in which W_ij = 1/n_l if yi = yj = l;\n",
    "            otherwise W_ij = 0 (default fisher_score = false)\n",
    "        reliefF: {boolean}\n",
    "            indicates whether to build the affinity matrix in a reliefF way, NH(x) and NM(x,y) denotes a set of\n",
    "            k nearest points to x with the same class as x, and a different class (the class y), respectively.\n",
    "            W_ij = 1 if i = j; W_ij = 1/k if x_j \\in NH(x_i); W_ij = -1/(c-1)k if x_j \\in NM(x_i, y) (default reliefF = false)\n",
    "    Output\n",
    "    ------\n",
    "    W: {sparse matrix}, shape (n_samples, n_samples)\n",
    "        output affinity matrix W\n",
    "    \"\"\"\n",
    "\n",
    "    # default metric is 'cosine'\n",
    "    if 'metric' not in kwargs.keys():\n",
    "        kwargs['metric'] = 'cosine'\n",
    "\n",
    "    # default neighbor mode is 'knn' and default neighbor size is 5\n",
    "    if 'neighbor_mode' not in kwargs.keys():\n",
    "        kwargs['neighbor_mode'] = 'knn'\n",
    "    if kwargs['neighbor_mode'] == 'knn' and 'k' not in kwargs.keys():\n",
    "        kwargs['k'] = 5\n",
    "    if kwargs['neighbor_mode'] == 'supervised' and 'k' not in kwargs.keys():\n",
    "        kwargs['k'] = 5\n",
    "    if kwargs['neighbor_mode'] == 'supervised' and 'y' not in kwargs.keys():\n",
    "        print ('Warning: label is required in the supervised neighborMode!!!')\n",
    "        exit(0)\n",
    "\n",
    "    # default weight mode is 'binary', default t in heat kernel mode is 1\n",
    "    if 'weight_mode' not in kwargs.keys():\n",
    "        kwargs['weight_mode'] = 'binary'\n",
    "    if kwargs['weight_mode'] == 'heat_kernel':\n",
    "        if kwargs['metric'] != 'euclidean':\n",
    "            kwargs['metric'] = 'euclidean'\n",
    "        if 't' not in kwargs.keys():\n",
    "            kwargs['t'] = 1\n",
    "    elif kwargs['weight_mode'] == 'cosine':\n",
    "        if kwargs['metric'] != 'cosine':\n",
    "            kwargs['metric'] = 'cosine'\n",
    "\n",
    "    # default fisher_score and reliefF mode are 'false'\n",
    "    if 'fisher_score' not in kwargs.keys():\n",
    "        kwargs['fisher_score'] = False\n",
    "    if 'reliefF' not in kwargs.keys():\n",
    "        kwargs['reliefF'] = False\n",
    "\n",
    "    n_samples, n_features = np.shape(X)\n",
    "\n",
    "    # choose 'knn' neighbor mode\n",
    "    if kwargs['neighbor_mode'] == 'knn':\n",
    "        k = kwargs['k']\n",
    "        if kwargs['weight_mode'] == 'binary':\n",
    "            if kwargs['metric'] == 'euclidean':\n",
    "                # compute pairwise euclidean distances\n",
    "                D = pairwise_distances(X)\n",
    "                D **= 2\n",
    "                # sort the distance matrix D in ascending order\n",
    "                dump = np.sort(D, axis=1)\n",
    "                idx = np.argsort(D, axis=1)\n",
    "                # choose the k-nearest neighbors for each instance\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                G = np.zeros((n_samples*(k+1), 3))\n",
    "                G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "                G[:, 1] = np.ravel(idx_new, order='F')\n",
    "                G[:, 2] = 1\n",
    "                # build the sparse affinity matrix W\n",
    "                W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "                bigger = np.transpose(W) > W\n",
    "                W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "                return W\n",
    "\n",
    "            elif kwargs['metric'] == 'cosine':\n",
    "                # normalize the data first\n",
    "                X_normalized = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "                for i in range(n_samples):\n",
    "                    X[i, :] = X[i, :]/max(1e-12, X_normalized[i])\n",
    "                # compute pairwise cosine distances\n",
    "                D_cosine = np.dot(X, np.transpose(X))\n",
    "                # sort the distance matrix D in descending order\n",
    "                dump = np.sort(-D_cosine, axis=1)\n",
    "                idx = np.argsort(-D_cosine, axis=1)\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                G = np.zeros((n_samples*(k+1), 3))\n",
    "                G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "                G[:, 1] = np.ravel(idx_new, order='F')\n",
    "                G[:, 2] = 1\n",
    "                # build the sparse affinity matrix W\n",
    "                W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "                bigger = np.transpose(W) > W\n",
    "                W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "                return W\n",
    "\n",
    "        elif kwargs['weight_mode'] == 'heat_kernel':\n",
    "            t = kwargs['t']\n",
    "            # compute pairwise euclidean distances\n",
    "            D = pairwise_distances(X)\n",
    "            D **= 2\n",
    "            # sort the distance matrix D in ascending order\n",
    "            dump = np.sort(D, axis=1)\n",
    "            idx = np.argsort(D, axis=1)\n",
    "            idx_new = idx[:, 0:k+1]\n",
    "            dump_new = dump[:, 0:k+1]\n",
    "            # compute the pairwise heat kernel distances\n",
    "            dump_heat_kernel = np.exp(-dump_new/(2*t*t))\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "            G[:, 1] = np.ravel(idx_new, order='F')\n",
    "            G[:, 2] = np.ravel(dump_heat_kernel, order='F')\n",
    "            # build the sparse affinity matrix W\n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W\n",
    "\n",
    "        elif kwargs['weight_mode'] == 'cosine':\n",
    "            # normalize the data first\n",
    "            X_normalized = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "            for i in range(n_samples):\n",
    "                    X[i, :] = X[i, :]/max(1e-12, X_normalized[i])\n",
    "            # compute pairwise cosine distances\n",
    "            D_cosine = np.dot(X, np.transpose(X))\n",
    "            # sort the distance matrix D in ascending order\n",
    "            dump = np.sort(-D_cosine, axis=1)\n",
    "            idx = np.argsort(-D_cosine, axis=1)\n",
    "            idx_new = idx[:, 0:k+1]\n",
    "            dump_new = -dump[:, 0:k+1]\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            G[:, 0] = np.tile(np.arange(n_samples), (k+1, 1)).reshape(-1)\n",
    "            G[:, 1] = np.ravel(idx_new, order='F')\n",
    "            G[:, 2] = np.ravel(dump_new, order='F')\n",
    "            # build the sparse affinity matrix W\n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W\n",
    "\n",
    "    # choose supervised neighborMode\n",
    "    elif kwargs['neighbor_mode'] == 'supervised':\n",
    "        k = kwargs['k']\n",
    "        # get true labels and the number of classes\n",
    "        y = kwargs['y']\n",
    "        label = np.unique(y)\n",
    "        n_classes = np.unique(y).size\n",
    "        # construct the weight matrix W in a fisherScore way, W_ij = 1/n_l if yi = yj = l, otherwise W_ij = 0\n",
    "        if kwargs['fisher_score'] is True:\n",
    "            W = lil_matrix((n_samples, n_samples))\n",
    "            for i in range(n_classes):\n",
    "                class_idx = (y == label[i])\n",
    "                class_idx_all = (class_idx[:, np.newaxis] & class_idx[np.newaxis, :])\n",
    "                W[class_idx_all] = 1.0/np.sum(np.sum(class_idx))\n",
    "            return W\n",
    "\n",
    "        # construct the weight matrix W in a reliefF way, NH(x) and NM(x,y) denotes a set of k nearest\n",
    "        # points to x with the same class as x, a different class (the class y), respectively. W_ij = 1 if i = j;\n",
    "        # W_ij = 1/k if x_j \\in NH(x_i); W_ij = -1/(c-1)k if x_j \\in NM(x_i, y)\n",
    "        if kwargs['reliefF'] is True:\n",
    "            # when xj in NH(xi)\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            id_now = 0\n",
    "            for i in range(n_classes):\n",
    "                class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                D = pairwise_distances(X[class_idx, :])\n",
    "                D **= 2\n",
    "                idx = np.argsort(D, axis=1)\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                n_smp_class = (class_idx[idx_new[:]]).size\n",
    "                if len(class_idx) <= k:\n",
    "                    k = len(class_idx) - 1\n",
    "                G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                G[id_now:n_smp_class+id_now, 2] = 1.0/k\n",
    "                id_now += n_smp_class\n",
    "            W1 = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            # when i = j, W_ij = 1\n",
    "            for i in range(n_samples):\n",
    "                W1[i, i] = 1\n",
    "            # when x_j in NM(x_i, y)\n",
    "            G = np.zeros((n_samples*k*(n_classes - 1), 3))\n",
    "            id_now = 0\n",
    "            for i in range(n_classes):\n",
    "                class_idx1 = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                X1 = X[class_idx1, :]\n",
    "                for j in range(n_classes):\n",
    "                    if label[j] != label[i]:\n",
    "                        class_idx2 = np.column_stack(np.where(y == label[j]))[:, 0]\n",
    "                        X2 = X[class_idx2, :]\n",
    "                        D = pairwise_distances(X1, X2)\n",
    "                        idx = np.argsort(D, axis=1)\n",
    "                        idx_new = idx[:, 0:k]\n",
    "                        n_smp_class = len(class_idx1)*k\n",
    "                        G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx1, (k, 1)).reshape(-1)\n",
    "                        G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx2[idx_new[:]], order='F')\n",
    "                        G[id_now:n_smp_class+id_now, 2] = -1.0/((n_classes-1)*k)\n",
    "                        id_now += n_smp_class\n",
    "            W2 = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W2) > W2\n",
    "            W2 = W2 - W2.multiply(bigger) + np.transpose(W2).multiply(bigger)\n",
    "            W = W1 + W2\n",
    "            return W\n",
    "\n",
    "        if kwargs['weight_mode'] == 'binary':\n",
    "            if kwargs['metric'] == 'euclidean':\n",
    "                G = np.zeros((n_samples*(k+1), 3))\n",
    "                id_now = 0\n",
    "                for i in range(n_classes):\n",
    "                    class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                    # compute pairwise euclidean distances for instances in class i\n",
    "                    D = pairwise_distances(X[class_idx, :])\n",
    "                    D **= 2\n",
    "                    # sort the distance matrix D in ascending order for instances in class i\n",
    "                    idx = np.argsort(D, axis=1)\n",
    "                    idx_new = idx[:, 0:k+1]\n",
    "                    n_smp_class = len(class_idx)*(k+1)\n",
    "                    G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                    G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                    G[id_now:n_smp_class+id_now, 2] = 1\n",
    "                    id_now += n_smp_class\n",
    "                # build the sparse affinity matrix W\n",
    "                W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "                bigger = np.transpose(W) > W\n",
    "                W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "                return W\n",
    "\n",
    "            if kwargs['metric'] == 'cosine':\n",
    "                # normalize the data first\n",
    "                X_normalized = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "                for i in range(n_samples):\n",
    "                    X[i, :] = X[i, :]/max(1e-12, X_normalized[i])\n",
    "                G = np.zeros((n_samples*(k+1), 3))\n",
    "                id_now = 0\n",
    "                for i in range(n_classes):\n",
    "                    class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                    # compute pairwise cosine distances for instances in class i\n",
    "                    D_cosine = np.dot(X[class_idx, :], np.transpose(X[class_idx, :]))\n",
    "                    # sort the distance matrix D in descending order for instances in class i\n",
    "                    idx = np.argsort(-D_cosine, axis=1)\n",
    "                    idx_new = idx[:, 0:k+1]\n",
    "                    n_smp_class = len(class_idx)*(k+1)\n",
    "                    G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                    G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                    G[id_now:n_smp_class+id_now, 2] = 1\n",
    "                    id_now += n_smp_class\n",
    "                # build the sparse affinity matrix W\n",
    "                W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "                bigger = np.transpose(W) > W\n",
    "                W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "                return W\n",
    "\n",
    "        elif kwargs['weight_mode'] == 'heat_kernel':\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            id_now = 0\n",
    "            for i in range(n_classes):\n",
    "                class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                # compute pairwise cosine distances for instances in class i\n",
    "                D = pairwise_distances(X[class_idx, :])\n",
    "                D **= 2\n",
    "                # sort the distance matrix D in ascending order for instances in class i\n",
    "                dump = np.sort(D, axis=1)\n",
    "                idx = np.argsort(D, axis=1)\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                dump_new = dump[:, 0:k+1]\n",
    "                t = kwargs['t']\n",
    "                # compute pairwise heat kernel distances for instances in class i\n",
    "                dump_heat_kernel = np.exp(-dump_new/(2*t*t))\n",
    "                n_smp_class = len(class_idx)*(k+1)\n",
    "                G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                G[id_now:n_smp_class+id_now, 2] = np.ravel(dump_heat_kernel, order='F')\n",
    "                id_now += n_smp_class\n",
    "            # build the sparse affinity matrix W\n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W\n",
    "\n",
    "        elif kwargs['weight_mode'] == 'cosine':\n",
    "            # normalize the data first\n",
    "            X_normalized = np.power(np.sum(X*X, axis=1), 0.5)\n",
    "            for i in range(n_samples):\n",
    "                X[i, :] = X[i, :]/max(1e-12, X_normalized[i])\n",
    "            G = np.zeros((n_samples*(k+1), 3))\n",
    "            id_now = 0\n",
    "            for i in range(n_classes):\n",
    "                class_idx = np.column_stack(np.where(y == label[i]))[:, 0]\n",
    "                # compute pairwise cosine distances for instances in class i\n",
    "                D_cosine = np.dot(X[class_idx, :], np.transpose(X[class_idx, :]))\n",
    "                # sort the distance matrix D in descending order for instances in class i\n",
    "                dump = np.sort(-D_cosine, axis=1)\n",
    "                idx = np.argsort(-D_cosine, axis=1)\n",
    "                idx_new = idx[:, 0:k+1]\n",
    "                dump_new = -dump[:, 0:k+1]\n",
    "                n_smp_class = len(class_idx)*(k+1)\n",
    "                G[id_now:n_smp_class+id_now, 0] = np.tile(class_idx, (k+1, 1)).reshape(-1)\n",
    "                G[id_now:n_smp_class+id_now, 1] = np.ravel(class_idx[idx_new[:]], order='F')\n",
    "                G[id_now:n_smp_class+id_now, 2] = np.ravel(dump_new, order='F')\n",
    "                id_now += n_smp_class\n",
    "            # build the sparse affinity matrix W\n",
    "            W = csc_matrix((G[:, 2], (G[:, 0], G[:, 1])), shape=(n_samples, n_samples))\n",
    "            bigger = np.transpose(W) > W\n",
    "            W = W - W.multiply(bigger) + np.transpose(W).multiply(bigger)\n",
    "            return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T07:32:31.344508Z",
     "start_time": "2022-12-08T07:32:31.308905Z"
    },
    "code_folding": [
     0,
     9,
     15,
     22,
     29,
     43,
     65,
     85,
     95,
     105
    ]
   },
   "outputs": [],
   "source": [
    "#函数\n",
    "def getRelevance(data,name):#计算相关性\n",
    "    a = data[data[name] == 1][\"longevity influence\"].mean()\n",
    "    b = data[data[name] == 0][\"longevity influence\"].mean()\n",
    "    \n",
    "    c = 1-a\n",
    "    d = 1-b\n",
    "    return pow((a-b),2)+pow((c-d),2)\n",
    "\n",
    "def GM_score(x,y): #计算GM 传入numpy\n",
    "    cm1 = confusion_matrix(x,y)\n",
    "    sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    return sensitivity1,specificity1\n",
    "\n",
    "def getAncestors(name):\n",
    "    global relativeList\n",
    "    for relative in DAG.columns:\n",
    "        if(DAG.loc[relative,name] == 1):\n",
    "            relativeList.append(relative)\n",
    "            getAncestors(relative)\n",
    "\n",
    "def getDescendants(name):\n",
    "    global relativeList\n",
    "    for relative in DAG.columns:\n",
    "        if(DAG.loc[name,relative] == 1):\n",
    "            relativeList.append(relative)\n",
    "            getAncestors(relative)\n",
    "\n",
    "def HIP(x): #传入实例，返回保留特征name\n",
    "    global relativeList\n",
    "    dropSet = set()\n",
    "    for name in DAG.columns:\n",
    "        relativeList = []\n",
    "        if(x[name] == 1):\n",
    "            getAncestors(name)\n",
    "        else:\n",
    "            getDescendants(name)\n",
    "        for removeName in set(relativeList):\n",
    "            dropSet.add(removeName)\n",
    "        \n",
    "    return list(set(DAG.columns)-dropSet)\n",
    "\n",
    "def MR(x):\n",
    "    global pathList\n",
    "    dropSet = set()\n",
    "    returnList = []\n",
    "    for name in DAG.columns:\n",
    "        pathList = []\n",
    "        if(x[name] == 1):#找到所有至根节点路径\n",
    "            getPathsToRoot([],name)\n",
    "            for path in pathList:\n",
    "                #保留相关性最高特征，其它特征加入dropSet\n",
    "                dropSet.update(Relevance[path].sort_values(ascending=False).index[1:])\n",
    "                #returnList.append(Relevance[path].sort_values(ascending=False).index[0])\n",
    "        else:\n",
    "            getPathsToLeft([],name)\n",
    "            for path in pathList:\n",
    "                #保留相关性最高特征，其它特征加入dropSet\n",
    "                dropSet.update(Relevance[path].sort_values(ascending=False).index[1:])\n",
    "                #returnList.aend(Relevance[path].sort_values(ascending=False).index[0])\n",
    "        #print(pathList)\n",
    "    return list(set(DAG.columns)-dropSet)\n",
    "    #return list(set(returnList))\n",
    "\n",
    "def HIP_MR(x):\n",
    "    global pathList\n",
    "    returnSet = set()\n",
    "    for name in DAG.columns:\n",
    "        if(x[name] == 1):#找到所有至根节点路径 删除相关性小于等于当前节点的特征\n",
    "            getPathsToRoot([],name)\n",
    "            for path in pathList:\n",
    "                #删除相关性小于等于当前节点的特征\n",
    "                threshold = Relevance[name]\n",
    "                temp = Relevance[Relevance > threshold][path].index.tolist()\n",
    "                returnSet.update(set(temp.append(name)))\n",
    "        else:\n",
    "            getPathsToLeft([],name)\n",
    "            for path in pathList:\n",
    "                #删除相关性小于等于当前节点的特征\n",
    "                threshold = Relevance[name]\n",
    "                temp = Relevance[Relevance > threshold][path].index.tolist()\n",
    "                returnSet.update(set(temp.append(name)))\n",
    "    return list(returnSet)\n",
    "\n",
    "def myknn(train,label,test):\n",
    "    maxJcd = 0\n",
    "    prediction = 0\n",
    "    for i in range(train.shape[0]):\n",
    "        temp = jaccard_score(train.iloc[i,:],test)\n",
    "        if(temp > maxJcd):\n",
    "            prediction = label[i]\n",
    "            maxJcd = temp\n",
    "    return prediction\n",
    "\n",
    "def getPathsToRoot(path,name):#传入list 方便递归\n",
    "    global pathList\n",
    "    flag = 0\n",
    "    path.append(name)\n",
    "    for anc in DAG.columns:\n",
    "        if(DAG.loc[anc,name] == 1):\n",
    "            getPathsToRoot(copy.copy(path),anc)\n",
    "            flag = 1\n",
    "    if(flag == 0):\n",
    "        pathList.append(path)\n",
    "def getPathsToLeft(path,name):#传入list 方便递归\n",
    "    global pathList\n",
    "    flag = 0\n",
    "    path.append(name)\n",
    "    for dec in DAG.columns:\n",
    "        if(DAG.loc[name,dec] == 1):\n",
    "            flag = 1\n",
    "            getPathsToLeft(copy.copy(path),dec)\n",
    "    if(flag == 0):\n",
    "        pathList.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T07:32:30.328810Z",
     "start_time": "2022-12-08T07:32:30.309863Z"
    }
   },
   "outputs": [],
   "source": [
    "dataList = [\"MM/MM-BP.csv\",\"MM/MM-CC.csv\",\"MM/MM-MF.csv\",\"MM/MM-BPCC.csv\",\n",
    "            \"MM/MM-BPMF.csv\",\"MM/MM-CCMF.csv\",\"MM/MM-BPCCMF.csv\",\n",
    "           \"CE/CE-BP.csv\",\"CE/CE-CC.csv\",\"CE/CE-MF.csv\",\"CE/CE-BPCC.csv\",\n",
    "            \"CE/CE-BPMF.csv\",\"CE/CE-CCMF.csv\",\"CE/CE-BPCCMF.csv\",\n",
    "           \"DM/DM-BP.csv\",\"DM/DM-CC.csv\",\"DM/DM-MF.csv\",\"DM/DM-BPCC.csv\",\n",
    "            \"DM/DM-BPMF.csv\",\"DM/DM-CCMF.csv\",\"DM/DM-BPCCMF.csv\",\n",
    "           \"SC/SC-BP.csv\",\"SC/SC-CC.csv\",\"SC/SC-MF.csv\",\"SC/SC-BPCC.csv\",\n",
    "            \"SC/SC-BPMF.csv\",\"SC/SC-CCMF.csv\",\"SC/SC-BPCCMF.csv\"]\n",
    "dataList = [\"SportsTweetst.csv\",\"SportsTweetsc.csv\",\"NYDailyheadings.csv\",\"Stumbleupon.csv\",\"Cities.csv\"]\n",
    "dataName = \"Stumbleupon.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T07:33:35.160133Z",
     "start_time": "2022-12-08T07:33:07.591045Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Li\\AppData\\Local\\Temp\\ipykernel_16264\\3973917611.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data[\"longevity influence\"] = label\n"
     ]
    }
   ],
   "source": [
    "#加载数据 预处理\n",
    "data = pd.read_csv(\"../data/real_world_datasets/Datasets/\"+dataName,index_col=None,encoding='gbk')\n",
    "if(dataName == \"Cities.csv\"):\n",
    "    data[\"longevity influence\"] = data[\"longevity influence\"].apply(lambda x : 0 if x < 2e+09 else 1)\n",
    "label = data[\"longevity influence\"]\n",
    "#删除无用列\n",
    "data = data.drop([\"longevity influence\"],axis=1)\n",
    "\n",
    "#初始化基因本体的DAG\n",
    "DAG = pd.read_csv(\"../data/real_world_datasets/Hierarchy/\"+dataName,index_col=0)\n",
    "\n",
    "#过滤低纬度特征\n",
    "for c in data.columns:\n",
    "    data[c] = data[c].astype('int')\n",
    "    if(data[c].sum() < 3):\n",
    "        data.drop(c,axis=1,inplace=True)\n",
    "#DAG = DAG.loc[data.columns,data.columns]\n",
    "\n",
    "#计算相关性\n",
    "data[\"longevity influence\"] = label\n",
    "Relevance = pd.Series(0.0,index=DAG.columns)\n",
    "# for name in DAG.columns:\n",
    "#     Relevance[name] = getRelevance(data,name)\n",
    "data = data.drop([\"longevity influence\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T08:13:25.672442Z",
     "start_time": "2022-12-08T07:56:37.137849Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1891\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m     clf \u001b[38;5;241m=\u001b[39m make_pipeline(StandardScaler(), SVC(gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     40\u001b[0m     clf\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m---> 41\u001b[0m     predicetList\u001b[38;5;241m.\u001b[39mappend(\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(selectFeatures)))[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicetList)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(Y_test)\n",
      "File \u001b[1;32mc:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:251\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 251\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mc:\\users\\li\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:333\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    319\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    323\u001b[0m (\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 333\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#训练\n",
    "pathList = []\n",
    "relativeList = []\n",
    "sensitivity = []\n",
    "specificity = []\n",
    "F1 = []\n",
    "AUC = []\n",
    "numList = []\n",
    "\n",
    "#10折交叉验证\n",
    "kf = KFold(n_splits=3,shuffle=True)\n",
    "for train_index ,test_index in kf.split(data):\n",
    "    trainData = data.iloc[train_index,:]\n",
    "    testData = data.iloc[test_index,:]\n",
    "    Y_train = label.values[train_index] #用于训练模型\n",
    "    Y_test = label.values[test_index]#用于交叉验证\n",
    "    predicetList = []\n",
    "    \n",
    "    \n",
    "    for i in range(testData.shape[0]):  #对每一个样本进行特征选择和预测\n",
    "        global pathList\n",
    "        global relativeList\n",
    "        \n",
    "        selectFeatures = data.columns[100:]\n",
    "        #selectFeatures = HIP(testData.iloc[i,:]) #HIP特征选择\n",
    "        #selectFeatures = MR(testData.iloc[i,:]) #MR特征选择\n",
    "        #selectFeatures = HIP_MR(testData.iloc[i,:]) \n",
    "        print(len(selectFeatures))\n",
    "        if(len(selectFeatures) == 0):\n",
    "            selectFeatures = DAG.columns\n",
    "        else:\n",
    "            numList.append(len(selectFeatures))\n",
    "        X_train = trainData.loc[:,selectFeatures]\n",
    "        X_test = testData.loc[:,selectFeatures].iloc[i,:]\n",
    "        \n",
    "#         gnb = GaussianNB()\n",
    "#         predicetList.append(gnb.fit(X_train, Y_train).predict(X_test.values.reshape(1,len(selectFeatures)))[0])#把当前样本预测结果加入List\n",
    "        from sklearn.svm import SVC\n",
    "        clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "        clf.fit(X_train, Y_train)\n",
    "        predicetList.append(clf.fit(X_train, Y_train).predict(X_test.values.reshape(1,len(selectFeatures)))[0])\n",
    "        \n",
    "    print(predicetList)\n",
    "    print(Y_test)\n",
    "    sensi,speci= GM_score(np.array(predicetList),Y_test)\n",
    "    sensitivity.append(sensi)\n",
    "    specificity.append(speci)\n",
    "    F1.append(f1_score(np.array(predicetList),Y_test))\n",
    "    try:\n",
    "        AUC.append(roc_auc_score(np.array(predicetList),Y_test))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "a = np.nanmean(sensitivity)\n",
    "b = np.nanmean(specificity)\n",
    "print(\"sensitivity\")\n",
    "print(a)\n",
    "print(\"specificity\")\n",
    "print(b)\n",
    "print(\"GM\")\n",
    "print(round(math.sqrt(a*b)*100,1))\n",
    "print(\"AUC\")\n",
    "print(round(np.nanmean(AUC)*100,1))\n",
    "res.loc[dataName,\"spnsi\"] = round(a*100,1)\n",
    "res.loc[dataName,\"speci\"] = round(b*100,1)\n",
    "res.loc[dataName,\"GM\"] = round(math.sqrt(a*b)*100,1)\n",
    "res.loc[dataName,\"f1\"] = round(np.nanmean(F1)*100,1)\n",
    "res.loc[dataName,\"AUC\"] = round(np.nanmean(AUC)*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T08:13:26.479871Z",
     "start_time": "2022-12-08T08:13:26.459928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity\n",
      "nan\n",
      "specificity\n",
      "nan\n",
      "GM\n",
      "nan\n",
      "AUC\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Li\\AppData\\Local\\Temp\\ipykernel_16264\\3586323371.py:1: RuntimeWarning: Mean of empty slice\n",
      "  a = np.nanmean(sensitivity)\n",
      "C:\\Users\\Li\\AppData\\Local\\Temp\\ipykernel_16264\\3586323371.py:2: RuntimeWarning: Mean of empty slice\n",
      "  b = np.nanmean(specificity)\n",
      "C:\\Users\\Li\\AppData\\Local\\Temp\\ipykernel_16264\\3586323371.py:10: RuntimeWarning: Mean of empty slice\n",
      "  print(round(np.nanmean(AUC)*100,1))\n",
      "C:\\Users\\Li\\AppData\\Local\\Temp\\ipykernel_16264\\3586323371.py:14: RuntimeWarning: Mean of empty slice\n",
      "  res.loc[dataName,\"f1\"] = round(np.nanmean(F1)*100,1)\n",
      "C:\\Users\\Li\\AppData\\Local\\Temp\\ipykernel_16264\\3586323371.py:15: RuntimeWarning: Mean of empty slice\n",
      "  res.loc[dataName,\"AUC\"] = round(np.nanmean(AUC)*100,1)\n"
     ]
    }
   ],
   "source": [
    "a = np.nanmean(sensitivity)\n",
    "b = np.nanmean(specificity)\n",
    "print(\"sensitivity\")\n",
    "print(a)\n",
    "print(\"specificity\")\n",
    "print(b)\n",
    "print(\"GM\")\n",
    "print(round(math.sqrt(a*b)*100,1))\n",
    "print(\"AUC\")\n",
    "print(round(np.nanmean(AUC)*100,1))\n",
    "res.loc[dataName,\"spnsi\"] = round(a*100,1)\n",
    "res.loc[dataName,\"speci\"] = round(b*100,1)\n",
    "res.loc[dataName,\"GM\"] = round(math.sqrt(a*b)*100,1)\n",
    "res.loc[dataName,\"f1\"] = round(np.nanmean(F1)*100,1)\n",
    "res.loc[dataName,\"AUC\"] = round(np.nanmean(AUC)*100,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
